#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤çˆ¬è™«AIåˆ†ææ–¹æ³•è°ƒç”¨é—®é¢˜
"""

import os
import re

def fix_crawler_ai_calls():
    """ä¿®å¤æ‰€æœ‰çˆ¬è™«çš„AIåˆ†ææ–¹æ³•è°ƒç”¨"""
    print("ğŸ”§ ä¿®å¤çˆ¬è™«AIåˆ†ææ–¹æ³•è°ƒç”¨...")
    
    crawlers = [
        "newsnow-python/crawlers/jin10.py",
        "newsnow-python/crawlers/wallstreet.py", 
        "newsnow-python/crawlers/fastbull.py",
        "newsnow-python/crawlers/gelonghui.py"
    ]
    
    for crawler_file in crawlers:
        if not os.path.exists(crawler_file):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {crawler_file}")
            continue
            
        try:
            with open(crawler_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            original_content = content
            
            # ä¿®å¤æ–¹æ³•è°ƒç”¨
            fixes = [
                # ä¿®å¤ generate_comprehensive_analysis å‚æ•°
                (
                    r'self\.finance_analyzer\.generate_comprehensive_analysis\(\s*text=([^,]+),\s*title=([^,]+),\s*searxng_results=([^)]+)\)',
                    r'self.finance_analyzer.generate_comprehensive_analysis(title=\2, content=\1, search_results=\3)'
                ),
                # ä¿®å¤ analyze_market_news å‚æ•°
                (
                    r'self\.finance_analyzer\.analyze_market_news\(\s*text=([^,]+),\s*title=([^,]+),\s*searxng_results=([^)]+)\)',
                    r'self.finance_analyzer.generate_comprehensive_analysis(title=\2, content=\1, search_results=\3)'
                ),
                # ä¿®å¤ analyze_article è°ƒç”¨
                (
                    r'self\.finance_analyzer\.analyze_article\([^)]+\)',
                    r'self.finance_analyzer.generate_comprehensive_analysis(title=title, content=content, search_results=article_detail.get("search_results", []))'
                ),
                # ä¿®å¤å…¶ä»–å¯èƒ½çš„è°ƒç”¨
                (
                    r'analysis_result = self\.finance_analyzer\.analyze_market_news\(',
                    r'analysis_result = self.finance_analyzer.generate_comprehensive_analysis('
                )
            ]
            
            for old_pattern, new_pattern in fixes:
                if re.search(old_pattern, content):
                    content = re.sub(old_pattern, new_pattern, content)
                    print(f"âœ… ä¿®å¤äº†æ–¹æ³•è°ƒç”¨: {crawler_file}")
            
            # å¦‚æœå†…å®¹æœ‰å˜åŒ–ï¼Œå†™å›æ–‡ä»¶
            if content != original_content:
                with open(crawler_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… å·²æ›´æ–°: {crawler_file}")
            else:
                print(f"â„¹ï¸ æ— éœ€ä¿®å¤: {crawler_file}")
                
        except Exception as e:
            print(f"âŒ ä¿®å¤å¤±è´¥: {crawler_file} - {e}")

def add_missing_methods():
    """ä¸ºå¢å¼ºç‰ˆAIæœåŠ¡æ·»åŠ ç¼ºå¤±çš„å…¼å®¹æ–¹æ³•"""
    print("\nğŸ”§ ä¸ºAIæœåŠ¡æ·»åŠ å…¼å®¹æ–¹æ³•...")
    
    service_file = "newsnow-python/utils/enhanced_ai_service.py"
    
    try:
        with open(service_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ·»åŠ å…¼å®¹æ–¹æ³•
        additional_methods = '''
    
    def analyze_article(self, article_data):
        """å…¼å®¹æ—§æ¥å£çš„æ–‡ç« åˆ†ææ–¹æ³•"""
        title = article_data.get('title', '')
        content = article_data.get('content', '')
        search_results = article_data.get('search_results', [])
        
        return self.generate_comprehensive_analysis(
            title=title,
            content=content,
            search_results=search_results
        )
'''
        
        # åœ¨ç±»çš„æœ€åæ·»åŠ å…¼å®¹æ–¹æ³•
        if 'def analyze_article(self, article_data):' not in content:
            # æ‰¾åˆ°ç±»çš„ç»“å°¾ï¼Œåœ¨æœ€åä¸€ä¸ªæ–¹æ³•åæ·»åŠ 
            class_end_pattern = r'(\s+def analyze_market_news\(self, text, title=None, searxng_results=None\):.*?return self\.generate_comprehensive_analysis\(title or "å¸‚åœºæ–°é—»", text, searxng_results\))'
            
            if re.search(class_end_pattern, content, re.DOTALL):
                content = re.sub(
                    class_end_pattern,
                    r'\1' + additional_methods,
                    content,
                    flags=re.DOTALL
                )
                
                with open(service_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                print(f"âœ… å·²æ·»åŠ å…¼å®¹æ–¹æ³•åˆ°: {service_file}")
            else:
                print(f"âš ï¸ æ— æ³•æ‰¾åˆ°æ’å…¥ç‚¹: {service_file}")
        else:
            print(f"â„¹ï¸ å…¼å®¹æ–¹æ³•å·²å­˜åœ¨: {service_file}")
            
    except Exception as e:
        print(f"âŒ æ·»åŠ å…¼å®¹æ–¹æ³•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ ä¿®å¤çˆ¬è™«AIåˆ†æè°ƒç”¨é—®é¢˜...")
    print("=" * 50)
    
    # 1. ä¿®å¤çˆ¬è™«AIæ–¹æ³•è°ƒç”¨
    fix_crawler_ai_calls()
    
    # 2. æ·»åŠ ç¼ºå¤±çš„å…¼å®¹æ–¹æ³•
    add_missing_methods()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ä¿®å¤å®Œæˆï¼")
    print("ğŸ’¡ å»ºè®®é‡æ–°æµ‹è¯•çˆ¬è™«: python3 test_all_crawlers.py")

if __name__ == "__main__":
    main() 