#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡AIåˆ†æå¤„ç†å™¨
å¤„ç†æ•°æ®åº“ä¸­æœªåˆ†æçš„æ–‡ç« 
"""

import os
import sys
import time
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.enhanced_ai_service import EnhancedFinanceAnalyzer
from db.sqlite_client import SQLiteClient

class BatchAIProcessor:
    """æ‰¹é‡AIåˆ†æå¤„ç†å™¨"""
    
    def __init__(self):
        self.analyzer = EnhancedFinanceAnalyzer()
        self.db_client = SQLiteClient()
    
    def process_unanalyzed_articles(self, batch_size=5, delay_between_batches=120):
        """
        æ‰¹é‡å¤„ç†æœªåˆ†æçš„æ–‡ç« 
        
        Args:
            batch_size (int): æ¯æ‰¹å¤„ç†çš„æ–‡ç« æ•°é‡
            delay_between_batches (int): æ‰¹æ¬¡é—´å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        """
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡AIåˆ†æå¤„ç†...")
        print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {batch_size}, æ‰¹æ¬¡é—´å»¶è¿Ÿ: {delay_between_batches}ç§’")
        
        try:
            # è·å–æœªåˆ†æçš„æ–‡ç« 
            unanalyzed_articles = self.db_client.get_unprocessed_articles(limit=100)
            
            if not unanalyzed_articles:
                print("âœ… æ²¡æœ‰éœ€è¦åˆ†æçš„æ–‡ç« ")
                return
            
            print(f"ğŸ“ æ‰¾åˆ° {len(unanalyzed_articles)} ç¯‡æœªåˆ†æçš„æ–‡ç« ")
            
            # åˆ†æ‰¹å¤„ç†
            total_processed = 0
            total_success = 0
            
            for i in range(0, len(unanalyzed_articles), batch_size):
                batch = unanalyzed_articles[i:i + batch_size]
                batch_num = (i // batch_size) + 1
                
                print(f"\nğŸ“¦ å¤„ç†ç¬¬ {batch_num} æ‰¹ ({len(batch)} ç¯‡æ–‡ç« )...")
                
                batch_success = 0
                for article in batch:
                    try:
                        article_id = article.get('id')
                        title = article.get('title', '')
                        content = article.get('content', '')
                        
                        print(f"ğŸ” åˆ†ææ–‡ç« : {title[:50]}...")
                        
                        # æ‰§è¡ŒAIåˆ†æ
                        analysis_result = self.analyzer.generate_comprehensive_analysis(
                            title=title,
                            content=content,
                            search_results=[]
                        )
                        
                        if analysis_result:
                            # æ›´æ–°æ•°æ®åº“
                            success = self.db_client.update_article_analysis(article_id, analysis_result)
                            if success:
                                print(f"âœ… åˆ†æå®Œæˆ: {title[:30]}...")
                                batch_success += 1
                                total_success += 1
                            else:
                                print(f"âŒ ä¿å­˜å¤±è´¥: {title[:30]}...")
                        else:
                            print(f"âš ï¸ åˆ†æå¤±è´¥: {title[:30]}...")
                        
                        total_processed += 1
                        
                        # æ–‡ç« é—´çŸ­æš‚å»¶è¿Ÿ
                        time.sleep(5)
                        
                    except Exception as e:
                        print(f"âŒ å¤„ç†æ–‡ç« å¼‚å¸¸: {e}")
                        continue
                
                print(f"ğŸ“Š ç¬¬ {batch_num} æ‰¹å®Œæˆ: {batch_success}/{len(batch)} æˆåŠŸ")
                
                # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆé™¤äº†æœ€åä¸€æ‰¹ï¼‰
                if i + batch_size < len(unanalyzed_articles):
                    print(f"â° ç­‰å¾… {delay_between_batches} ç§’åå¤„ç†ä¸‹ä¸€æ‰¹...")
                    time.sleep(delay_between_batches)
            
            print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
            print(f"ğŸ“Š æ€»è®¡å¤„ç†: {total_processed} ç¯‡")
            print(f"âœ… æˆåŠŸåˆ†æ: {total_success} ç¯‡")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {(total_success/total_processed*100):.1f}%")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")

def main():
    """ä¸»å‡½æ•°"""
    processor = BatchAIProcessor()
    processor.process_unanalyzed_articles(
        batch_size=3,  # æ¯æ‰¹3ç¯‡æ–‡ç« 
        delay_between_batches=90  # æ‰¹æ¬¡é—´ç­‰å¾…90ç§’
    )

if __name__ == "__main__":
    # æ‰‹åŠ¨åŠ è½½ç¯å¢ƒå˜é‡
    env_file = ".env"
    if os.path.exists(env_file):
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()
    
    main()
