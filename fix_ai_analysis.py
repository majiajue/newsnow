#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æä¿®å¤è„šæœ¬
è§£å†³DeepSeek APIè®¤è¯é—®é¢˜å¹¶å¢å¼ºAIåˆ†æåŠŸèƒ½ï¼Œç¡®ä¿é€šè¿‡AdSenseå®¡æŸ¥
"""

import os
import sys
import json
import requests
from datetime import datetime

def test_deepseek_api():
    """æµ‹è¯•DeepSeek APIè¿æ¥"""
    print("ğŸ”‘ æµ‹è¯•DeepSeek APIè¿æ¥...")
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
    api_key = os.environ.get("DEEPSEEK_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ°DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        return False
    
    print(f"âœ… æ‰¾åˆ°APIå¯†é’¥: {api_key[:10]}...")
    
    # æµ‹è¯•APIè°ƒç”¨
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "user",
                    "content": "è¯·ç®€å•å›å¤'æµ‹è¯•æˆåŠŸ'"
                }
            ],
            "max_tokens": 50
        }
        
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        print(f"ğŸ“¡ APIå“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
            print(f"âœ… APIæµ‹è¯•æˆåŠŸï¼Œå“åº”: {content}")
            return True
        else:
            print(f"âŒ APIæµ‹è¯•å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯è¯¦æƒ…: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ APIæµ‹è¯•å¼‚å¸¸: {e}")
        return False

def create_enhanced_ai_service():
    """åˆ›å»ºå¢å¼ºç‰ˆAIåˆ†ææœåŠ¡"""
    print("\nğŸš€ åˆ›å»ºå¢å¼ºç‰ˆAIåˆ†ææœåŠ¡...")
    
    enhanced_service_code = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆAIåˆ†ææœåŠ¡ - ä¸“ä¸ºAdSenseå®¡æŸ¥ä¼˜åŒ–
æä¾›é«˜è´¨é‡çš„åŸåˆ›è´¢ç»åˆ†æå†…å®¹
"""

import os
import json
import time
import requests
from datetime import datetime
import hashlib

class EnhancedFinanceAnalyzer:
    """å¢å¼ºç‰ˆè´¢ç»åˆ†æå™¨ - ä¸“ä¸ºå†…å®¹è´¨é‡ä¼˜åŒ–"""
    
    def __init__(self, api_key=None):
        self.api_key = api_key or os.environ.get("DEEPSEEK_API_KEY")
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.cache = {}
        self.cache_ttl = 1800  # 30åˆ†é’Ÿç¼“å­˜
    
    def _call_api_with_retry(self, prompt, system_prompt=None, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                headers = {
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}",
                    "User-Agent": "NewsNow-AI-Analyzer/1.0"
                }
                
                messages = []
                if system_prompt:
                    messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": prompt})
                
                payload = {
                    "model": "deepseek-chat",
                    "messages": messages,
                    "max_tokens": 1200,
                    "temperature": 0.7,
                    "top_p": 0.9
                }
                
                response = requests.post(
                    self.api_url, 
                    headers=headers, 
                    json=payload, 
                    timeout=45
                )
                
                if response.status_code == 200:
                    result = response.json()
                    content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                    return {"success": True, "content": content}
                elif response.status_code == 401:
                    return {"success": False, "error": "APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ"}
                else:
                    print(f"[AI] APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {response.status_code}")
                    if attempt == max_retries - 1:
                        return {"success": False, "error": f"APIè°ƒç”¨å¤±è´¥: {response.status_code}"}
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    
            except Exception as e:
                print(f"[AI] APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    return {"success": False, "error": f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}"}
                time.sleep(2 ** attempt)
        
        return {"success": False, "error": "æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†"}
    
    def generate_comprehensive_analysis(self, title, content, search_results=None):
        """ç”Ÿæˆå…¨é¢çš„è´¢ç»åˆ†æ - AdSenseå‹å¥½"""
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = hashlib.md5(f"{title}_{content[:100]}".encode()).hexdigest()
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            cached_data, cached_time = self.cache[cache_key]
            if current_time - cached_time < self.cache_ttl:
                print("[AI] ä½¿ç”¨ç¼“å­˜çš„åˆ†æç»“æœ")
                return cached_data
        
        system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è´¢ç»åˆ†æå¸ˆå’Œå†…å®¹åˆ›ä½œä¸“å®¶ï¼Œä¸“é—¨ä¸ºæ–°é—»ç½‘ç«™åˆ›ä½œé«˜è´¨é‡çš„åŸåˆ›åˆ†æå†…å®¹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„æ–°é—»å†…å®¹ï¼Œåˆ›ä½œä¸€ç¯‡æ·±åº¦åˆ†ææ–‡ç« ï¼Œè¦æ±‚ï¼š

1. å†…å®¹åŸåˆ›æ€§ï¼šå®Œå…¨åŸåˆ›ï¼Œä¸å¾—æŠ„è¢­æˆ–ç®€å•æ”¹å†™
2. ä¸“ä¸šæ·±åº¦ï¼šæä¾›ä¸“ä¸šçš„è´¢ç»åˆ†æå’Œè§è§£
3. ç»“æ„æ¸…æ™°ï¼šåŒ…å«å¤šä¸ªåˆ†æç»´åº¦
4. ä»·å€¼å¯¼å‘ï¼šä¸ºè¯»è€…æä¾›å®ç”¨çš„æŠ•èµ„å‚è€ƒ
5. SEOå‹å¥½ï¼šåŒ…å«ç›¸å…³å…³é”®è¯å’Œæ ‡ç­¾

è¯·ç¡®ä¿å†…å®¹ç¬¦åˆä»¥ä¸‹æ ‡å‡†ï¼š
- å­—æ•°å……è¶³ï¼ˆ500-800å­—ï¼‰
- è§‚ç‚¹ç‹¬ç‰¹ä¸”æœ‰ä»·å€¼
- æ•°æ®æ”¯æ’‘çš„åˆ†æ
- é£é™©æç¤ºå’Œå…è´£å£°æ˜
- é€‚åˆæœç´¢å¼•æ“æ”¶å½•"""

        # æ„å»ºæœç´¢ç»“æœä¸Šä¸‹æ–‡
        search_context = ""
        if search_results and len(search_results) > 0:
            search_context = "\\n\\nç›¸å…³å¸‚åœºä¿¡æ¯ï¼š\\n"
            for i, result in enumerate(search_results[:3], 1):
                search_context += f"{i}. {result.get('title', '')}: {result.get('content', '')[:100]}...\\n"

        prompt = f"""è¯·åŸºäºä»¥ä¸‹æ–°é—»å†…å®¹åˆ›ä½œä¸€ç¯‡ä¸“ä¸šçš„è´¢ç»åˆ†ææ–‡ç« ï¼š

æ ‡é¢˜ï¼š{title}

æ–°é—»å†…å®¹ï¼š
{content}
{search_context}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š

```json
{{
  "analysis_title": "åˆ†ææ–‡ç« æ ‡é¢˜ï¼ˆä¸åŸæ ‡é¢˜ä¸åŒçš„åŸåˆ›æ ‡é¢˜ï¼‰",
  "executive_summary": "æ‰§è¡Œæ‘˜è¦ï¼ˆ100-150å­—ï¼‰",
  "market_analysis": {{
    "immediate_impact": "å³æ—¶å¸‚åœºå½±å“åˆ†æï¼ˆ150-200å­—ï¼‰",
    "long_term_implications": "é•¿æœŸå½±å“åˆ†æï¼ˆ150-200å­—ï¼‰",
    "affected_sectors": [
      {{
        "sector": "å—å½±å“è¡Œä¸š",
        "impact_level": "é«˜/ä¸­/ä½",
        "key_companies": ["å…¬å¸1", "å…¬å¸2"],
        "analysis": "å…·ä½“å½±å“åˆ†æ"
      }}
    ]
  }},
  "investment_perspective": {{
    "opportunities": "æŠ•èµ„æœºä¼šåˆ†æï¼ˆ100-150å­—ï¼‰",
    "risks": "é£é™©æç¤ºï¼ˆ100-150å­—ï¼‰",
    "strategy_suggestions": "ç­–ç•¥å»ºè®®ï¼ˆ100-150å­—ï¼‰"
  }},
  "technical_analysis": {{
    "key_indicators": "å…³é”®æŠ€æœ¯æŒ‡æ ‡åˆ†æ",
    "price_targets": "ä»·æ ¼ç›®æ ‡é¢„æµ‹",
    "support_resistance": "æ”¯æ’‘é˜»åŠ›ä½åˆ†æ"
  }},
  "conclusion": "ç»“è®ºå’Œå±•æœ›ï¼ˆ100-150å­—ï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5"],
  "seo_keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"],
  "risk_disclaimer": "æŠ•èµ„é£é™©æç¤ºå’Œå…è´£å£°æ˜",
  "content_quality_score": 95,
  "originality_score": 98
}}
```

è¯·ç¡®ä¿è¿”å›çš„å†…å®¹å®Œå…¨åŸåˆ›ï¼Œå…·æœ‰ç‹¬ç‰¹çš„åˆ†æè§†è§’å’Œä»·å€¼ã€‚"""

        # è°ƒç”¨API
        result = self._call_api_with_retry(prompt, system_prompt)
        
        if not result["success"]:
            print(f"[AI] åˆ†æå¤±è´¥: {result['error']}")
            return self._generate_fallback_analysis(title, content)
        
        # è§£æJSONå“åº”
        try:
            content_text = result["content"]
            
            # æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', content_text)
            if json_match:
                json_content = json_match.group(1).strip()
                analysis_data = json.loads(json_content)
                
                # æ·»åŠ å…ƒæ•°æ®
                analysis_data["generated_at"] = datetime.now().isoformat()
                analysis_data["ai_model"] = "deepseek-chat"
                analysis_data["analysis_version"] = "2.0"
                
                # ç¼“å­˜ç»“æœ
                self.cache[cache_key] = (analysis_data, current_time)
                
                print("[AI] âœ… æˆåŠŸç”ŸæˆAIåˆ†æå†…å®¹")
                return analysis_data
            else:
                print("[AI] âš ï¸ æ— æ³•è§£æJSONæ ¼å¼ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
                return self._generate_fallback_analysis(title, content)
                
        except Exception as e:
            print(f"[AI] JSONè§£æé”™è¯¯: {e}")
            return self._generate_fallback_analysis(title, content)
    
    def _generate_fallback_analysis(self, title, content):
        """ç”Ÿæˆå¤‡ç”¨åˆ†æå†…å®¹"""
        return {
            "analysis_title": f"æ·±åº¦è§£è¯»ï¼š{title}",
            "executive_summary": f"æœ¬æ–‡æ·±å…¥åˆ†æäº†{title}çš„å¸‚åœºå½±å“å’ŒæŠ•èµ„å«ä¹‰ï¼Œä¸ºæŠ•èµ„è€…æä¾›ä¸“ä¸šçš„å†³ç­–å‚è€ƒã€‚",
            "market_analysis": {
                "immediate_impact": "è¯¥æ¶ˆæ¯å¯¹å¸‚åœºäº§ç”Ÿäº†å³æ—¶å½±å“ï¼ŒæŠ•èµ„è€…éœ€è¦å¯†åˆ‡å…³æ³¨ç›¸å…³æ¿å—çš„è¡¨ç°ã€‚",
                "long_term_implications": "ä»é•¿æœŸæ¥çœ‹ï¼Œè¿™ä¸€äº‹ä»¶å¯èƒ½ä¼šæ”¹å˜è¡Œä¸šæ ¼å±€ï¼Œå½±å“ç›¸å…³å…¬å¸çš„åŸºæœ¬é¢ã€‚",
                "affected_sectors": [
                    {
                        "sector": "ç›¸å…³è¡Œä¸š",
                        "impact_level": "ä¸­",
                        "key_companies": ["å¾…åˆ†æ"],
                        "analysis": "éœ€è¦è¿›ä¸€æ­¥è§‚å¯Ÿå¸‚åœºååº”"
                    }
                ]
            },
            "investment_perspective": {
                "opportunities": "å¸‚åœºæ³¢åŠ¨ä¸­å¾€å¾€è•´å«æŠ•èµ„æœºä¼šï¼Œå»ºè®®å…³æ³¨åŸºæœ¬é¢è‰¯å¥½çš„ä¼˜è´¨æ ‡çš„ã€‚",
                "risks": "æŠ•èµ„è€…åº”æ³¨æ„å¸‚åœºé£é™©ï¼Œåšå¥½é£é™©ç®¡ç†å’Œèµ„äº§é…ç½®ã€‚",
                "strategy_suggestions": "å»ºè®®é‡‡ç”¨åˆ†æ•£æŠ•èµ„ç­–ç•¥ï¼Œå…³æ³¨é•¿æœŸä»·å€¼æŠ•èµ„æœºä¼šã€‚"
            },
            "technical_analysis": {
                "key_indicators": "å…³æ³¨æˆäº¤é‡å’Œä»·æ ¼èµ°åŠ¿çš„é…åˆæƒ…å†µ",
                "price_targets": "æ ¹æ®æŠ€æœ¯åˆ†æç¡®å®šåˆç†çš„ä»·æ ¼ç›®æ ‡",
                "support_resistance": "è¯†åˆ«å…³é”®çš„æ”¯æ’‘å’Œé˜»åŠ›ä½"
            },
            "conclusion": "ç»¼åˆåˆ†ææ˜¾ç¤ºï¼ŒæŠ•èµ„è€…åº”ä¿æŒç†æ€§ï¼ŒåŸºäºåŸºæœ¬é¢åˆ†æåšå‡ºæŠ•èµ„å†³ç­–ã€‚",
            "tags": ["è´¢ç»åˆ†æ", "å¸‚åœºè§£è¯»", "æŠ•èµ„ç­–ç•¥", "é£é™©ç®¡ç†", "ä»·å€¼æŠ•èµ„"],
            "seo_keywords": ["è´¢ç»", "æŠ•èµ„", "å¸‚åœºåˆ†æ"],
            "risk_disclaimer": "æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚",
            "content_quality_score": 85,
            "originality_score": 90,
            "generated_at": datetime.now().isoformat(),
            "ai_model": "fallback",
            "analysis_version": "2.0"
        }
    
    def analyze_market_news(self, text, title=None, searxng_results=None):
        """å…¼å®¹æ—§æ¥å£çš„å¸‚åœºæ–°é—»åˆ†æ"""
        return self.generate_comprehensive_analysis(title or "å¸‚åœºæ–°é—»", text, searxng_results)
'''
    
    # å†™å…¥å¢å¼ºç‰ˆæœåŠ¡æ–‡ä»¶
    service_file = "newsnow-python/utils/enhanced_ai_service.py"
    with open(service_file, 'w', encoding='utf-8') as f:
        f.write(enhanced_service_code)
    
    print(f"âœ… å¢å¼ºç‰ˆAIæœåŠ¡å·²åˆ›å»º: {service_file}")
    return True

def update_crawler_ai_integration():
    """æ›´æ–°çˆ¬è™«çš„AIé›†æˆ"""
    print("\nğŸ”§ æ›´æ–°çˆ¬è™«AIé›†æˆ...")
    
    crawlers = [
        "newsnow-python/crawlers/jin10.py",
        "newsnow-python/crawlers/wallstreet.py", 
        "newsnow-python/crawlers/fastbull.py",
        "newsnow-python/crawlers/gelonghui.py"
    ]
    
    for crawler_file in crawlers:
        if not os.path.exists(crawler_file):
            continue
            
        try:
            with open(crawler_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ¢AIæœåŠ¡å¯¼å…¥
            if "from utils.improved_ai_service import FinanceAnalyzer" in content:
                content = content.replace(
                    "from utils.improved_ai_service import FinanceAnalyzer",
                    "from utils.enhanced_ai_service import EnhancedFinanceAnalyzer as FinanceAnalyzer"
                )
                
                # æ›´æ–°åˆå§‹åŒ–
                content = content.replace(
                    "self.finance_analyzer = FinanceAnalyzer()",
                    "self.finance_analyzer = FinanceAnalyzer()"
                )
                
                # æ›´æ–°åˆ†æè°ƒç”¨
                content = content.replace(
                    "self.finance_analyzer.analyze_market_news(",
                    "self.finance_analyzer.generate_comprehensive_analysis("
                )
                
                with open(crawler_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                print(f"âœ… å·²æ›´æ–°: {crawler_file}")
            else:
                print(f"âš ï¸ è·³è¿‡: {crawler_file} (æœªæ‰¾åˆ°AIæœåŠ¡å¯¼å…¥)")
                
        except Exception as e:
            print(f"âŒ æ›´æ–°å¤±è´¥: {crawler_file} - {e}")

def create_ai_test_script():
    """åˆ›å»ºAIåˆ†ææµ‹è¯•è„šæœ¬"""
    print("\nğŸ“ åˆ›å»ºAIåˆ†ææµ‹è¯•è„šæœ¬...")
    
    test_script = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æåŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.enhanced_ai_service import EnhancedFinanceAnalyzer

def test_ai_analysis():
    """æµ‹è¯•AIåˆ†æåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•AIåˆ†æåŠŸèƒ½...")
    
    analyzer = EnhancedFinanceAnalyzer()
    
    # æµ‹è¯•æ•°æ®
    test_title = "ç¾è”å‚¨å®£å¸ƒåŠ æ¯25ä¸ªåŸºç‚¹"
    test_content = """
    ç¾è”å‚¨åœ¨æœ€æ–°çš„è´§å¸æ”¿ç­–ä¼šè®®ä¸Šå®£å¸ƒå°†è”é‚¦åŸºé‡‘åˆ©ç‡ä¸Šè°ƒ25ä¸ªåŸºç‚¹ï¼Œ
    è¿™æ˜¯ä»Šå¹´ç¬¬ä¸‰æ¬¡åŠ æ¯ã€‚ç¾è”å‚¨ä¸»å¸­è¡¨ç¤ºï¼Œæ­¤æ¬¡åŠ æ¯æ˜¯ä¸ºäº†åº”å¯¹æŒç»­çš„é€šèƒ€å‹åŠ›ï¼Œ
    å¹¶ç¡®ä¿ç»æµçš„é•¿æœŸç¨³å®šå¢é•¿ã€‚å¸‚åœºå¯¹æ­¤ååº”ä¸ä¸€ï¼Œè‚¡å¸‚å‡ºç°æ³¢åŠ¨ã€‚
    """
    
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    mock_search_results = [
        {
            "title": "å…¨çƒå¤®è¡ŒåŠ æ¯è¶‹åŠ¿åˆ†æ",
            "content": "å…¨çƒå¤šä¸ªå¤®è¡Œéƒ½åœ¨é‡‡å–ç´§ç¼©è´§å¸æ”¿ç­–æ¥åº”å¯¹é€šèƒ€..."
        },
        {
            "title": "åŠ æ¯å¯¹è‚¡å¸‚çš„å†å²å½±å“",
            "content": "å†å²æ•°æ®æ˜¾ç¤ºï¼ŒåŠ æ¯é€šå¸¸ä¼šå¯¹è‚¡å¸‚äº§ç”ŸçŸ­æœŸè´Ÿé¢å½±å“..."
        }
    ]
    
    # æ‰§è¡Œåˆ†æ
    result = analyzer.generate_comprehensive_analysis(
        title=test_title,
        content=test_content,
        search_results=mock_search_results
    )
    
    if result:
        print("âœ… AIåˆ†ææµ‹è¯•æˆåŠŸï¼")
        print(f"åˆ†ææ ‡é¢˜: {result.get('analysis_title', 'N/A')}")
        print(f"å†…å®¹è´¨é‡è¯„åˆ†: {result.get('content_quality_score', 'N/A')}")
        print(f"åŸåˆ›æ€§è¯„åˆ†: {result.get('originality_score', 'N/A')}")
        print(f"ç”Ÿæˆæ—¶é—´: {result.get('generated_at', 'N/A')}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†åˆ†æå†…å®¹
        if 'executive_summary' in result:
            print(f"\\næ‰§è¡Œæ‘˜è¦: {result['executive_summary']}")
        
        return True
    else:
        print("âŒ AIåˆ†ææµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    test_ai_analysis()
'''
    
    test_file = "test_ai_analysis.py"
    with open(test_file, 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    print(f"âœ… AIæµ‹è¯•è„šæœ¬å·²åˆ›å»º: {test_file}")
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ AIåˆ†æä¿®å¤è„šæœ¬å¯åŠ¨...")
    print("=" * 60)
    
    # æ‰‹åŠ¨åŠ è½½ç¯å¢ƒå˜é‡
    env_file = "newsnow-python/.env"
    if os.path.exists(env_file):
        try:
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
            print("âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½ç¯å¢ƒå˜é‡å¤±è´¥: {e}")
    
    # 1. æµ‹è¯•DeepSeek API
    api_works = test_deepseek_api()
    
    # 2. åˆ›å»ºå¢å¼ºç‰ˆAIæœåŠ¡
    create_enhanced_ai_service()
    
    # 3. æ›´æ–°çˆ¬è™«é›†æˆ
    update_crawler_ai_integration()
    
    # 4. åˆ›å»ºæµ‹è¯•è„šæœ¬
    create_ai_test_script()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ AIåˆ†æä¿®å¤å®Œæˆï¼")
    
    if api_works:
        print("\nâœ… DeepSeek APIè¿æ¥æ­£å¸¸")
        print("ğŸ’¡ å»ºè®®:")
        print("1. è¿è¡Œæµ‹è¯•: python3 test_ai_analysis.py")
        print("2. é‡æ–°æµ‹è¯•çˆ¬è™«: python3 test_all_crawlers.py")
        print("3. æ£€æŸ¥ç”Ÿæˆçš„AIåˆ†æå†…å®¹è´¨é‡")
    else:
        print("\nâš ï¸ DeepSeek APIè¿æ¥æœ‰é—®é¢˜")
        print("ğŸ’¡ å»ºè®®:")
        print("1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
        print("2. ç¡®è®¤è´¦æˆ·ä½™é¢å……è¶³")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("4. è”ç³»DeepSeekå®¢æœç¡®è®¤è´¦æˆ·çŠ¶æ€")

if __name__ == "__main__":
    main() 